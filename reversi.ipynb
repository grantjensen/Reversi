{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metric-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reversi_board\n",
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aware-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class turnBoard(reversi_board.ReversiBoard):\n",
    "    def __init__(self, turn=2):\n",
    "        self.turn=turn\n",
    "        super(turnBoard, self).__init__()\n",
    "    \n",
    "    def changeTurn(self, turn):\n",
    "        #Maps 1->2 and 2->1\n",
    "        return (-(turn-1)+2)\n",
    "    \n",
    "    def push(self, p):\n",
    "        if p==-1: # pass turn\n",
    "            self.turn=self.changeTurn(self.turn)\n",
    "            return\n",
    "        else:\n",
    "            self.put_piece(p,self.turn)\n",
    "            self.turn=self.changeTurn(self.turn)\n",
    "            return\n",
    "        \n",
    "    \n",
    "    def isGameOver(self):\n",
    "        #Return 0 if draw, 1 if player whose turn it is wins, -1 if player whose turn it is loses, 2 if not over\n",
    "        if len(self.placable_positions(1))!=0:\n",
    "            return 2  # Not draw\n",
    "        if len(self.placable_positions(2))!=0:\n",
    "            return 2  # Not draw\n",
    "        counts=collections.Counter(self.board)\n",
    "        if counts[1]>counts[2]:  \n",
    "            if self.turn==1:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        elif counts[1]<counts[2]:\n",
    "            if self.turn==2:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def copy(self):\n",
    "        boardCopy=turnBoard(self.turn)\n",
    "        boardCopy.board=self.board.copy()\n",
    "        return boardCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "specified-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet\n",
    "import math\n",
    "x=0.75\n",
    "alpha=2\n",
    "c_puct=4\n",
    "class MCTS:\n",
    "    def __init__(self):\n",
    "        self.Q={}#Array for some given state as to the rewards for taking each action\n",
    "        self.N={}#Array for some given state as to the number of times each action has been visited from state\n",
    "        self.P={}#Policy vector for given state\n",
    "    \n",
    "    def search(self, s, nnet):\n",
    "        gameOver=s.isGameOver()\n",
    "        if gameOver!=2:  # Is game over?\n",
    "            return -gameOver\n",
    "        sh=s.board.tobytes()\n",
    "        if sh not in self.P.keys():  # Not visited\n",
    "            prediction=nnet.predict(tf.convert_to_tensor(np.reshape(s.board,(1,8,8),order='F')))\n",
    "            self.P[sh]=prediction[0][0]\n",
    "            v=prediction[1][0][0]\n",
    "            #Add dirichlet noise\n",
    "            \n",
    "            self.P[sh]=np.array(self.P[sh])\n",
    "            self.P[sh]=x*self.P[sh]+(1-x)*dirichlet.rvs(np.ones(len(self.P[sh]))*alpha)[0]\n",
    "            self.N[sh]=np.zeros(64)\n",
    "            self.Q[sh]=np.zeros(64)\n",
    "            return -v\n",
    "        \n",
    "        max_u, best_square = -float(\"inf\"), -1\n",
    "        for square in s.placable_positions(s.turn):\n",
    "            u=self.Q[sh][square]+c_puct*self.P[sh][square]*math.sqrt(sum(self.N[sh]))/(1+self.N[sh][square])\n",
    "            if u>max_u:\n",
    "                max_u=u\n",
    "                best_square=square\n",
    "        square=best_square\n",
    "        sp=s.copy()\n",
    "        sp.push(square)\n",
    "        v=self.search(sp, nnet)\n",
    "        self.Q[sh][best_square]=(self.N[sh][best_square]*self.Q[sh][best_square]+v)/(self.N[sh][best_square]+1)\n",
    "        self.N[sh][best_square]+=1\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "class ReversiModel:\n",
    "    def __init__(self):\n",
    "        inx = x=Input((8,8))\n",
    "        x=Reshape((8,8,1))(x)\n",
    "        for _ in range(10):  # Create residual layers\n",
    "            x=Conv2D(filters=64, kernel_size=(3,3), padding='same', data_format='channels_last')(x)\n",
    "            x=BatchNormalization(axis=3)(x)\n",
    "            x=Activation(\"relu\")(x)\n",
    "            \n",
    "        res_out=x\n",
    "        # Policy output\n",
    "        x=Conv2D(filters=2, kernel_size=1, data_format='channels_last')(res_out)\n",
    "        x=BatchNormalization(axis=3)(x)\n",
    "        x=Activation(\"relu\")(x)\n",
    "        x=Flatten()(x)\n",
    "        policy_out=Dense(8*8, activation=\"softmax\", name=\"policy_out\")(x)\n",
    "        self.model=policy_out\n",
    "        \n",
    "        #Value output\n",
    "        x=Conv2D(filters=1, kernel_size=1, data_format=\"channels_last\")(res_out)\n",
    "        x=BatchNormalization(axis=3)(x)\n",
    "        x=Activation(\"relu\")(x)\n",
    "        x=Flatten()(x)\n",
    "        value_out=Dense(1, activation='tanh', name='value_out')(x)\n",
    "        self.model=Model(inx, [policy_out, value_out], name='reversi_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "toxic-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeEpisode(nnet):\n",
    "    searchtime=0\n",
    "    examples=[]\n",
    "    s=turnBoard()\n",
    "    mcts=MCTS()\n",
    "    move=0\n",
    "    while True:\n",
    "        for _ in range(2):\n",
    "            mcts.search(s,nnet)\n",
    "        pi=mcts.P[s.board.tobytes()]\n",
    "        examples.append([s.board, pi, None])\n",
    "        legalmoves=s.placable_positions(s.turn)\n",
    "        if len(legalmoves)==0:\n",
    "            a=-1\n",
    "        else:\n",
    "            legalprobs=np.take(pi,legalmoves)\n",
    "            if move<30: #Temperature\n",
    "                legalprobs/=sum(legalprobs)\n",
    "                a=np.random.choice(legalmoves, p=legalprobs)\n",
    "            else:\n",
    "                a=legalmoves[np.argmax(legalprobs)]\n",
    "        s.push(a)\n",
    "        gameover=s.isGameOver()\n",
    "        if gameover!=2:\n",
    "            return assignRewards(examples, gameover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aerial-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignRewards(examples, reward):\n",
    "    for i in range(len(examples)-1,-1,-1):\n",
    "        examples[i][2]=reward\n",
    "        reward*=-1\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "identified-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.optimizer_v2.learning_rate_schedule import PiecewiseConstantDecay\n",
    "def policyIterSP(nnetIterStart=0):\n",
    "    learning_rate_fn = PiecewiseConstantDecay(boundaries=[20000, 40000, 50000], values=[1e-4, 5e-5, 2.5e-4, 1e-5])\n",
    "    optimizer=Adam(learning_rate_fn)\n",
    "    if nnetIterStart==0:\n",
    "        nnet=ReversiModel().model\n",
    "        nnet.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=optimizer)\n",
    "        loss=[]\n",
    "        value_out_loss=[]\n",
    "        policy_out_loss=[]\n",
    "    else:\n",
    "        nnet=load_model(\"models/model\"+str(nnetIterStart))\n",
    "        with open('models/loss.npy', 'rb') as f:\n",
    "            loss=np.load(f)\n",
    "            value_out_loss=np.load(f)\n",
    "            policy_out_loss=np.load(f)\n",
    "    for nnetIter in range(nnetIterStart, 1):\n",
    "        for ep in range(1):\n",
    "            episode=np.array(executeEpisode(nnet), dtype='O')\n",
    "            if ep==0:\n",
    "                examples=episode\n",
    "            else:\n",
    "                examples=np.concatenate((examples, episode))\n",
    "        new_nnet=clone_model(nnet)\n",
    "        new_nnet.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=optimizer)\n",
    "        np.random.shuffle(examples)\n",
    "        hist=modelFit(examples,new_nnet)\n",
    "        loss=np.append(loss,hist.history['loss'])\n",
    "        value_out_loss=np.append(value_out_loss,hist.history['value_out_loss'])\n",
    "        policy_out_loss=np.append(value_out_loss,hist.history['policy_out_loss'])\n",
    "        frac_win=pit(new_nnet, nnet)\n",
    "        if frac_win>0.55:\n",
    "            nnet=clone_model(new_nnet)\n",
    "            nnet.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=optimizer)\n",
    "        save_model(nnet, \"models/model\"+str(nnetIter+1))\n",
    "        return nnet\n",
    "        with open('models/loss.npy', 'wb') as f:\n",
    "            np.save(f, loss)\n",
    "            np.save(f, value_out_loss)\n",
    "            np.save(f, policy_out_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "romance-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFit(examples,nnet):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    c=[]\n",
    "    for i in range(len(examples)):\n",
    "        a.append(np.reshape(examples[i][0],(8,8),order='F'))\n",
    "        b.append(examples[i][1])\n",
    "        c.append(examples[i][2])\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "    c=np.array(c)\n",
    "    return nnet.fit(a,[b,c], epochs=10, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sacred-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move_gameplay(nnet, mcts, s):\n",
    "    for _ in range(2):\n",
    "        mcts.search(s,nnet)\n",
    "    pi=mcts.P[s.board.tobytes()]\n",
    "    legalmoves=s.placable_positions(s.turn)\n",
    "    if len(legalmoves)==0:\n",
    "        a=-1\n",
    "    else:\n",
    "        legalprobs=np.take(pi,legalmoves)\n",
    "        a=legalmoves[np.argmax(legalprobs)]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "funny-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit(nnet, new_nnet):\n",
    "    record=[0,0,0]#new_nnet wins, nnet wins, draws\n",
    "    for _ in range(1):\n",
    "        s=turnBoard()\n",
    "        mcts=MCTS()\n",
    "        new_mcts=MCTS()\n",
    "        while True:\n",
    "            a=choose_move_gameplay(nnet, mcts, s)\n",
    "            s.push(a)\n",
    "            gameOver=s.isGameOver()\n",
    "            if gameOver!=2:\n",
    "                if gameOver==1:\n",
    "                    record[0]+=1\n",
    "                elif gameOver==-1:\n",
    "                    record[1]+=1\n",
    "                else:\n",
    "                    record[2]+=1\n",
    "                break\n",
    "            a=choose_move_gameplay(new_nnet, new_mcts, s)\n",
    "            s.push(a)\n",
    "            gameOver=s.isGameOver()\n",
    "            if gameOver!=2:\n",
    "                if gameOver==1:\n",
    "                    record[1]+=1\n",
    "                elif gameOver==-1:\n",
    "                    record[0]+=1\n",
    "                else:\n",
    "                    record[2]+=1\n",
    "                break\n",
    "        s=turnBoard()\n",
    "        mcts=MCTS()\n",
    "        new_mcts=MCTS()\n",
    "        while True:\n",
    "            a=choose_move_gameplay(new_nnet, new_mcts, s)\n",
    "            s.push(a)\n",
    "            gameOver=s.isGameOver()\n",
    "            if gameOver!=2:\n",
    "                if gameOver==1:\n",
    "                    record[1]+=1\n",
    "                elif gameOver==-1:\n",
    "                    record[0]+=1\n",
    "                else:\n",
    "                    record[2]+=1\n",
    "                break\n",
    "            a=choose_move_gameplay(nnet, mcts, s)\n",
    "            s.push(a)\n",
    "            gameOver=s.isGameOver()\n",
    "            if gameOver!=2:\n",
    "                if gameOver==1:\n",
    "                    record[0]+=1\n",
    "                elif gameOver==-1:\n",
    "                    record[1]+=1\n",
    "                else:\n",
    "                    record[2]+=1\n",
    "                break\n",
    "    return record[0]/sum(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "proof-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model1/assets\n",
      "37.74581813812256\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "model=policyIterSP()\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "formed-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=load_model(\"models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "lesbian-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': {'class_name': 'PiecewiseConstantDecay',\n",
       "  'config': {'boundaries': [20000, 40000, 50000],\n",
       "   'values': [0.0001, 5e-05, 0.00025, 1e-05],\n",
       "   'name': None}},\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "alternative-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': {'class_name': 'PiecewiseConstantDecay',\n",
       "  'config': {'boundaries': [20000, 40000, 50000],\n",
       "   'values': [0.0001, 5e-05, 0.00025, 1e-05],\n",
       "   'name': None}},\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-label",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversi",
   "language": "python",
   "name": "reversi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
