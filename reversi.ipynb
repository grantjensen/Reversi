{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "metric-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reversi_board\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "aware-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class turnBoard(reversi_board.ReversiBoard):\n",
    "    def __init__(self, turn=2):\n",
    "        self.turn=turn\n",
    "        super(turnBoard, self).__init__()\n",
    "    \n",
    "    def changeTurn(self, turn):\n",
    "        #Maps 1->2 and 2->1\n",
    "        return (-(turn-1)+2)\n",
    "    \n",
    "    def push(self, p):\n",
    "        if p==-1: # pass turn\n",
    "            self.turn=self.changeTurn(self.turn)\n",
    "            return\n",
    "        else:\n",
    "            self.put_piece(p,self.turn)\n",
    "            self.turn=self.changeTurn(self.turn)\n",
    "            return\n",
    "        \n",
    "    \n",
    "    def isGameOver(self):\n",
    "        #Return 0 if draw, 1 if player whose turn it is wins, -1 if player whose turn it is loses, 2 if not over\n",
    "        if len(self.placable_positions(1))!=0:\n",
    "            return 2  # Not draw\n",
    "        if len(self.placable_positions(2))!=0:\n",
    "            return 2  # Not draw\n",
    "        counts=collections.Counter(self.board)\n",
    "        if counts[1]>counts[2]:  \n",
    "            if self.turn==1:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        elif counts[1]<counts[2]:\n",
    "            if self.turn==2:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "    \n",
    "    def copy(self):\n",
    "        boardCopy=turnBoard(self.turn)\n",
    "        boardCopy.board=self.board.copy()\n",
    "        return boardCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "specified-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet\n",
    "import math\n",
    "x=0.75\n",
    "alpha=2\n",
    "c_puct=4\n",
    "class MCTS:\n",
    "    def __init__(self):\n",
    "        self.Q={}#Array for some given state as to the rewards for taking each action\n",
    "        self.N={}#Array for some given state as to the number of times each action has been visited from state\n",
    "        self.P={}#Policy vector for given state\n",
    "    \n",
    "    def search(self, s, nnet):\n",
    "        gameOver=s.isGameOver()\n",
    "        if gameOver!=2:  # Is game over?\n",
    "            return -gameOver\n",
    "        sh=s.board.tobytes()\n",
    "        if sh not in self.P.keys():  # Not visited\n",
    "            prediction=nnet.predict(np.reshape(s.board,(1,8,8),order='F'))\n",
    "            self.P[sh]=prediction[0][0]\n",
    "            v=prediction[1][0][0]\n",
    "            #Add dirichlet noise\n",
    "            self.P[sh]=np.array(self.P[sh])\n",
    "            self.P[sh]=x*self.P[sh]+(1-x)*dirichlet.rvs(np.ones(len(self.P[sh]))*alpha)[0]\n",
    "            self.N[sh]=np.zeros(64)\n",
    "            self.Q[sh]=np.zeros(64)\n",
    "            return -v\n",
    "        \n",
    "        max_u, best_square = -float(\"inf\"), -1\n",
    "        for square in s.placable_positions(s.turn):\n",
    "            u=self.Q[sh][square]+c_puct*self.P[sh][square]*math.sqrt(sum(self.N[sh]))/(1+self.N[sh][square])\n",
    "            if u>max_u:\n",
    "                max_u=u\n",
    "                best_square=square\n",
    "        square=best_square\n",
    "        sp=s.copy()\n",
    "        sp.push(square)\n",
    "        v=self.search(sp, nnet)\n",
    "        self.Q[sh][best_square]=(self.N[sh][best_square]*self.Q[sh][best_square]+v)/(self.N[sh][best_square]+1)\n",
    "        self.N[sh][best_square]+=1\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "painted-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "class ReversiModel:\n",
    "    def __init__(self):\n",
    "        inx = x=Input((8,8))\n",
    "        x=Reshape((8,8,1))(x)\n",
    "        for _ in range(10):  # Create residual layers\n",
    "            x=Conv2D(filters=64, kernel_size=(3,3), padding='same', data_format='channels_last')(x)\n",
    "            x=BatchNormalization(axis=3)(x)\n",
    "            x=Activation(\"relu\")(x)\n",
    "            \n",
    "        res_out=x\n",
    "        # Policy output\n",
    "        x=Conv2D(filters=2, kernel_size=1, data_format='channels_last')(res_out)\n",
    "        x=BatchNormalization(axis=3)(x)\n",
    "        x=Activation(\"relu\")(x)\n",
    "        x=Flatten()(x)\n",
    "        policy_out=Dense(8*8, activation=\"softmax\", name=\"policy_out\")(x)\n",
    "        self.model=policy_out\n",
    "        \n",
    "        #Value output\n",
    "        x=Conv2D(filters=1, kernel_size=1, data_format=\"channels_last\")(res_out)\n",
    "        x=BatchNormalization(axis=3)(x)\n",
    "        x=Activation(\"relu\")(x)\n",
    "        x=Flatten()(x)\n",
    "        value_out=Dense(1, activation='tanh', name='value_out')(x)\n",
    "        self.model=Model(inx, [policy_out, value_out], name='reversi_model')\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "toxic-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeEpisode(nnet):\n",
    "    examples=[]\n",
    "    s=turnBoard()\n",
    "    mcts=MCTS()\n",
    "    \n",
    "    while True:\n",
    "        for _ in range(2):\n",
    "            mcts.search(s,nnet)\n",
    "        pi=mcts.P[s.board.tobytes()]\n",
    "        examples.append([s.board, pi, None])\n",
    "        legalmoves=s.placable_positions(s.turn)\n",
    "        if len(legalmoves)==0:\n",
    "            a=-1\n",
    "        else:\n",
    "            legalprobs=np.take(pi,legalmoves)\n",
    "            legalprobs/=sum(legalprobs)\n",
    "            a=np.random.choice(legalmoves, p=legalprobs)\n",
    "        s.push(a)\n",
    "        gameover=s.isGameOver()\n",
    "        if gameover!=2:\n",
    "            return assignRewards(examples, gameover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "aerial-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignRewards(examples, reward):\n",
    "    for i in range(len(examples)-1,-1,-1):\n",
    "        examples[i][2]=reward\n",
    "        reward*=-1\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "identified-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyIterSP():\n",
    "    nnet=ReversiModel().model\n",
    "    examples=[]\n",
    "    for _ in range(1):\n",
    "        for _ in range(2):\n",
    "            episode=executeEpisode(nnet)\n",
    "            if len(examples)==0:\n",
    "                examples=episode\n",
    "            else:\n",
    "                examples=np.concatenate((examples, episode))\n",
    "        new_nnet=clone_model(model)\n",
    "        new_nnet.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer='adam')\n",
    "        modelFit(examples,new_nnet)#Make sure the new_nnet is actually trained, and training is retained after return\n",
    "        frac_win=pit(new_nnet, nnet)\n",
    "        if frac_win>0.55:\n",
    "            nnet=new_nnet\n",
    "    return nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "romance-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFit(examples,nnet):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    c=[]\n",
    "    for _ in range(len(examples)):\n",
    "        a.append(np.reshape(examples[i][0],(8,8),order='F'))\n",
    "        b.append(examples[i][1])\n",
    "        c.append(examples[i][2])\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "    c=np.array(c)\n",
    "    nnet.fit(a,[b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "proof-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 44ms/step - loss: 4.7315 - policy_out_loss: 4.4082 - value_out_loss: 0.3233\n",
      "<keras.engine.functional.Functional object at 0x14bb9fca0> <keras.engine.functional.Functional object at 0x14d7d48e0>\n"
     ]
    }
   ],
   "source": [
    "def pit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sampling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversi",
   "language": "python",
   "name": "reversi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
